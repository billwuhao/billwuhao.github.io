<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="msvalidate.01" content="10807BE8A369314ADD132603D6E6055C">
  <meta name="baidu-site-verification" content="zzxKZjYogh">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"8.0.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="探索花花世界，追寻自己内心">
<meta property="og:type" content="website">
<meta property="og:title" content="吴明文的站点">
<meta property="og:url" content="http://example.com/page/285/">
<meta property="og:site_name" content="吴明文的站点">
<meta property="og:description" content="探索花花世界，追寻自己内心">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="吴明文">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/285/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>吴明文的站点 - 探索花花世界，追寻自己内心</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">吴明文的站点</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">探索花花世界，追寻自己内心</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">10</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">4</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">298</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="吴明文"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">吴明文</p>
  <div class="site-description" itemprop="description">探索花花世界，追寻自己内心</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">298</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-instagram fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.catb.org/~esr/faqs/hacker-howto.html" title="http:&#x2F;&#x2F;www.catb.org&#x2F;~esr&#x2F;faqs&#x2F;hacker-howto.html" rel="noopener" target="_blank">How To Become A Hacker</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.marxists.org/index.htm" title="https:&#x2F;&#x2F;www.marxists.org&#x2F;index.htm" rel="noopener" target="_blank">Marxists Internet Archive</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.gutenberg.org/wiki/Main_Page" title="https:&#x2F;&#x2F;www.gutenberg.org&#x2F;wiki&#x2F;Main_Page" rel="noopener" target="_blank">Project Gutenberg</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.shi-ci.com/" title="https:&#x2F;&#x2F;www.shi-ci.com&#x2F;" rel="noopener" target="_blank">中华诗词</a>
        </li>
    </ul>
  </div>

        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">
      

      
    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/statistics/statistics9-1d958e8e187b/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="吴明文">
      <meta itemprop="description" content="探索花花世界，追寻自己内心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴明文的站点">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/statistics/statistics9-1d958e8e187b/" class="post-title-link" itemprop="url">K-Means 算法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表</span>

      <time title="创建时间：2020-06-03 11:57:40" itemprop="dateCreated datePublished" datetime="2020-06-03T11:57:40+08:00">2020-06-03</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新</span>
        <time title="修改时间：2021-01-02 15:38:53" itemprop="dateModified" datetime="2021-01-02T15:38:53+08:00">2021-01-02</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" itemprop="url" rel="index"><span itemprop="name">数据分析</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">字数：</span>
      <span>2.2k</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p>内容主要来源：<strong>开课吧</strong>学习笔记整理。</p>
</blockquote>
<h2 id="十-K-Means-算法"><a href="#十-K-Means-算法" class="headerlink" title="十, K-Means 算法"></a>十, K-Means 算法</h2><h3 id="1-聚类"><a href="#1-聚类" class="headerlink" title="1, 聚类"></a>1, 聚类</h3><p>前面接触的算法, 都是<strong>监督学习</strong>, 即训练数据中自变量(特征)和因变量(结果)都是已知的, 用含有结果的训练集建立模型, 然后对未知结果的数据进行预测</p>
<p>聚类属于<strong>无监督学习</strong>, 训练数据中没有”已知结果的监督”. 聚类的目的, 就是通过已知样本数据的特征, 将数据划分为若干个类别, 每个类别成一个类簇, 使得同一个簇内的数据相似度越大, “物以类聚”, 不同簇之间的数据相似度越小, 聚类效果越好</p>
<p>聚类的样本相似度根据距离来度量</p>
<h3 id="2-K-Means"><a href="#2-K-Means" class="headerlink" title="2, K-Means"></a>2, K-Means</h3><p>即 K 均值算法, 是常见的聚类算法, 该算法将数据集分为 K 个簇, 每个簇使用簇内所有样本的均值来表示, 该均值称为”质心”</p>
<p>K-Means 算法的目标, 就是选择适合的质心, 使得每个簇内, 样本点距质心的距离尽可能的小, 从而保证簇内样本有较高相似度</p>
<p>算法实现步骤:</p>
<p>a, 从样本中选择 K 个点作为初始质心<br>b, 计算每个样本点到各个质心的距离, 将样本点划分到距离最近的质心所对应的簇中<br>c, 计算每个簇内所有样本的均值, 使用该均值作为新的质心<br>d, 重复 b 和 c, 重复一定次数质心一般会趋于稳定, 如果达到以下条件, 重复结束:<br>– 质心位置变化小于指定的阈值<br>– 达到最迭代环次数</p>
<p>对于算法的实现步骤, 我们有几个重要的疑问:</p>
<p>– 1.怎么评价质心是否达到了最佳位置?<br>– 2.初始质心随机选, 还是选在哪里?<br>– 3. K 值怎么定?  </p>
<h3 id="3-算法优化目标"><a href="#3-算法优化目标" class="headerlink" title="3, 算法优化目标"></a>3, 算法优化目标</h3><p>样本的相似度是根据距离来度量的, 一般使用簇内<strong>误差平方和</strong>(within-cluster SSE 簇惯性) 来作为优化算法的目标函数, 距离常用欧氏距离, 优化目标就是使 SSE 最小化:</p>
<p>$$S S E=\sum_{i=1}^{k} \sum_{j=1}^{m_{i}}\left(\left|x_{j}-\mu_{i}\right|^{2}\right)$$</p>
<p>k: 族的数量  </p>
<p>$m_{i}$: 第 i 个簇含有的样本数量 </p>
<p>${\mu}_{i}$: 第 i 个族的质心  </p>
<p>$\left|x_{j}-\mu_{i}\right|$: 第 i 个族中，每个样本  $x_{j}$  与质心 $\mu_{i}$  的距离</p>
<p>同一个数据集, 相同的簇数, SSE 越小, 通常质心位置更佳, 算法模型更好</p>
<h3 id="4-初始质心的影响"><a href="#4-初始质心的影响" class="headerlink" title="4, 初始质心的影响"></a>4, 初始质心的影响</h3><p>初始质心可以随机选择, 但由于算法是通过迭代初始质心一步步实现, 初始质心的位置受随机性影响, 算法训练的最终结果也会受到影响</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;YouYuan&#x27;</span> </span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.size&#x27;</span>] = <span class="number">12</span> </span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> </span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">生成数据:</span></span><br><span class="line"><span class="string">n_samples: 样本数量</span></span><br><span class="line"><span class="string">n_features: 特征数</span></span><br><span class="line"><span class="string">centers: 聚类中心</span></span><br><span class="line"><span class="string">cluster_std: 簇的标准差, 可以统一指定, 也分别指定</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">5</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line">x, y = make_blobs(n_samples=<span class="number">90</span>,</span><br><span class="line">                  n_features=<span class="number">2</span>,</span><br><span class="line">                  centers=centers,</span><br><span class="line">                  cluster_std=[<span class="number">2.2</span>, <span class="number">2.5</span>, <span class="number">2</span>],</span><br><span class="line">                  random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># x 是特征, y 是类别标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始数据</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">colors = np.array([<span class="string">&#x27;Coral&#x27;</span>, <span class="string">&#x27;SeaGreen&#x27;</span>, <span class="string">&#x27;RoyalBlue&#x27;</span>])</span><br><span class="line">plt.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], c=colors[y], marker=<span class="string">&#x27;.&#x27;</span>, label=<span class="string">&#x27;原始数据&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义绘制聚类结果的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_cluster</span>(<span class="params">model, train, test=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">global</span> colors  <span class="comment"># 使用上面的颜色</span></span><br><span class="line">    cc = model.cluster_centers_ <span class="comment"># 获取质心</span></span><br><span class="line">    label = model.labels_ <span class="comment"># 获取聚类结果的标签</span></span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    plt.scatter(cc[:, <span class="number">0</span>], <span class="comment"># 质心的 x 坐标</span></span><br><span class="line">                cc[:, <span class="number">1</span>], <span class="comment"># 质心的 y 坐标</span></span><br><span class="line">                marker=<span class="string">&#x27;*&#x27;</span>,</span><br><span class="line">                s=<span class="number">150</span>,</span><br><span class="line">                c=colors)</span><br><span class="line">    <span class="comment"># 绘制训练集</span></span><br><span class="line">    plt.scatter(train[:, <span class="number">0</span>], train[:, <span class="number">1</span>], marker=<span class="string">&#x27;.&#x27;</span>, c=colors[label])</span><br><span class="line">    <span class="comment"># 绘制测试集</span></span><br><span class="line">    <span class="keyword">if</span> test <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        y_hat = model.predict(test)</span><br><span class="line">        plt.scatter(test[:, <span class="number">0</span>], test[:, <span class="number">1</span>], marker=<span class="string">&#x27;+&#x27;</span>,</span><br><span class="line">                    s=<span class="number">150</span>, c=colors[y_hat])        </span><br><span class="line">    <span class="comment"># 标题</span></span><br><span class="line">    plt.title(<span class="string">f&#x27;SSE:<span class="subst">&#123;model.inertia_:<span class="number">.1</span>f&#125;</span> 迭代次数:<span class="subst">&#123;model.n_iter_&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">test = np.array([[<span class="number">6</span>, <span class="number">5</span>]])    </span><br><span class="line"><span class="comment"># 绘制不同初始质心的聚类结果</span></span><br><span class="line">seed = [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">5</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, i)</span><br><span class="line">    kmeans = KMeans(n_clusters=<span class="number">3</span>, <span class="comment"># 簇数</span></span><br><span class="line">                    init=<span class="string">&#x27;random&#x27;</span>, <span class="comment"># 初始化方式</span></span><br><span class="line">                    n_init=<span class="number">1</span>, <span class="comment"># 初始化质心组数</span></span><br><span class="line">                    random_state=seed[i<span class="number">-2</span>])</span><br><span class="line">    kmeans.fit(x)</span><br><span class="line">    plot_cluster(kmeans, x)</span><br><span class="line">    <span class="comment"># 测试结果</span></span><br><span class="line">    plot_cluster(kmeans, x, test)</span><br></pre></td></tr></table></figure>


<p><img src="https://wx2.sbimg.cn/2020/07/04/2O85J.md.png" alt="png"></p>
<p>从上图可以看出受初始化质心的影响, 聚类效果(SSE) 与 收敛速度(迭代次数) 会不同, 也即是可能会收敛到局部最小, 而不是整体最优; 同时, 也可以看出 SSE 越小, 整体结果越优, 越接近原始数据</p>
<h3 id="5-K-Means-优化"><a href="#5-K-Means-优化" class="headerlink" title="5, K-Means++ 优化"></a>5, K-Means++ 优化</h3><p>针对上述初始化质心造成的问题, 设置初始化多组质心可以得到缓解, 但通常限于聚类簇数较少的情况, 如果簇数较多, 可能就不会有效</p>
<p>于是有了 K-Means++, 选择初始化质心时, 不在随机选, 而是按下述步骤进行选择:</p>
<p>– 1, 从训练数据中随机选择一个样本点, 作为初始质心<br>– 2, 对任意一个非质心样本点 $x^{(i)}$, 计算 $x^{(i)}$ 与现有最近质心的距离 $D\left(x^{(i)}\right)$<br>– 3, 根据概率 $\frac{D\left(x^{(i)}\right)^{2}}{\sum_{j=1}^{m} D\left(x^{(j)}\right)^{2}}$ 最大, 来选择最远的一个样本点 $x^{(i)}$ 作为质心, m 为非质心样本点数量<br>– 4, 重复 2 和 3, 直到选择了 K 个质心为止</p>
<p>做了优化之后, 保证了初始质心不会集中, 而是分散在数据集中</p>
<p>下面试试 K-Means++ 的聚类效果:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kmeans = KMeans(n_clusters=<span class="number">3</span>, init=<span class="string">&#x27;k-means++&#x27;</span>, n_init=<span class="number">1</span>)</span><br><span class="line">kmeans.fit(x)</span><br><span class="line">plot_cluster(kmeans, x)</span><br></pre></td></tr></table></figure>


<p><img src="https://wx2.sbimg.cn/2020/07/04/2OnU8.png" alt="png"></p>
<h3 id="6-确定-K-值"><a href="#6-确定-K-值" class="headerlink" title="6, 确定 K 值"></a>6, 确定 K 值</h3><p>K 是超参数, 需要预先人为指定 </p>
<p>有时需要按照建模的需求和目的来选择聚类的个数, 但是 K 值选择不当, 聚类效果可能不佳. 例如实际 3 类, K 选了 10, 或者 K 无限制, 取值和样本点个数一样, 最后每个点一个类, SEE 为 0, 但是聚类已经毫无意义</p>
<p>如果不是硬性要求 K 的取值, 怎么确定最佳的 K 值呢? 一个比较好的方法就是<strong>肘部法则</strong>:</p>
<p>SEE 需要越小越好, K 又不能取太大, 我们可以看看他们之间的关系:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置列表储存 SSE</span></span><br><span class="line">sse = []</span><br><span class="line"><span class="comment"># K 值从 1~9 变化</span></span><br><span class="line">scope = <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> scope:</span><br><span class="line">    kmeans = KMeans(n_clusters=k)</span><br><span class="line">    kmeans.fit(x)</span><br><span class="line">    sse.append(kmeans.inertia_)</span><br><span class="line">    </span><br><span class="line">plt.xticks(scope)</span><br><span class="line">plt.plot(scope, sse, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/mathematical-statistics/output_70_0.png" alt="png"></p>
<p>从上图可以看出, K 增加, SSE 减小, 但当 K &gt; 3 时, K 再增加, SSE 减小变得缓慢, 所以 K 选择 3, 实际情况也是 3</p>
<h3 id="6-Mini-Batch-K-Means"><a href="#6-Mini-Batch-K-Means" class="headerlink" title="6, Mini Batch K-Means"></a>6, Mini Batch K-Means</h3><p>K-Means 每次迭代都会使用所有数据参与运算, 当数据集较大时, 会比较耗时. Mini Batch K-Means (小批量 K-Means) 算法每次迭代使用小批量样本训练, 逐批次累计的方式进行计算, 从而大大减少计算时间. 效果上, 通常只是略差于 K-Means</p>
<p>Mini Batch K-Means 算法实现步骤:</p>
<p>a, 从数据集中随机选择部分数据, 使用 K-Means 算法在这部分数据上聚类, 获取质心<br>b, 再从数据集中随机选择部分数据, 分别分配给最近的质心<br>c, 每个簇根据现有的数据集更新质心<br>d, 重复 b 和 c, 直到质心变化小于指定阈值或达到最大迭代次数</p>
<p>下面比较一下两个算法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MiniBatchKMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances_argmin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">400</span>, <span class="number">100</span>], [<span class="number">100</span>, <span class="number">400</span>]]</span><br><span class="line">x, y = make_blobs(n_samples=<span class="number">8000</span>, n_features=<span class="number">2</span>, centers=centers,</span><br><span class="line">                  cluster_std=<span class="number">120</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义函数, 用于计算模型训练时间</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">elapsed_time</span>(<span class="params">model, data</span>):</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    model.fit(data)</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="keyword">return</span> end - start</span><br><span class="line"></span><br><span class="line">n_clusters = <span class="built_in">len</span>(centers)</span><br><span class="line">kmeans = KMeans(n_clusters=n_clusters)</span><br><span class="line">mbk = MiniBatchKMeans(n_clusters=n_clusters,</span><br><span class="line">                      batch_size=<span class="number">200</span>, <span class="comment"># 小批量的大小</span></span><br><span class="line">                     n_init=<span class="number">10</span> <span class="comment"># 和 KMeans 统一为 10</span></span><br><span class="line">                     )</span><br><span class="line">kmeans_time = elapsed_time(kmeans, x)</span><br><span class="line">mbk_time = elapsed_time(mbk, x)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;K-Means耗时:&#x27;</span>, kmeans_time)</span><br><span class="line">print(<span class="string">&#x27;Mini Batch K-Means耗时:&#x27;</span>, mbk_time)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制聚类效果</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line">model = [kmeans, mbk]</span><br><span class="line"><span class="keyword">for</span> i, m <span class="keyword">in</span> <span class="built_in">enumerate</span>(model, start=<span class="number">1</span>):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, i)</span><br><span class="line">    plot_cluster(m, x)</span><br></pre></td></tr></table></figure>

<pre><code>K-Means耗时: 0.08678650856018066
Mini Batch K-Means耗时: 0.05485272407531738</code></pre>
<p><img src="https://wx2.sbimg.cn/2020/07/04/2ONKU.md.png" alt="png"></p>
<p>可见, 聚类耗时 K-Means 更多, 如果数据量很大, 耗时会更明显, 而聚类效果基本一样. 但发现颜色对不上, 这是因为质心的随机性, 聚类之后质心虽然最终落在相同的位置, 但是顺序不一致, 从而聚类的结果标签不一致, 即使是同一个算法, 运行几次, 标签结果也会不一致</p>
<p>我们将相同簇用相同的颜色绘制:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 定义列表, 用来保存两个模型预测结果</span></span><br><span class="line">y_hat_list = []</span><br><span class="line"><span class="keyword">for</span> i, m <span class="keyword">in</span> <span class="built_in">enumerate</span>(model, start=<span class="number">1</span>):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, i)</span><br><span class="line">    y_hat = m.predict(x)</span><br><span class="line">    <span class="keyword">if</span> m == mbk:</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        因为输出的质心顺序就是训练结果标签的顺序</span></span><br><span class="line"><span class="string">        故可以按 mbk 训练的质心, 去找 kmeans 训练的相同簇的质心</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        pairwise_distances_argmin(x, y) 解释:</span></span><br><span class="line"><span class="string">        依次取出数组 X 中的元素 x, </span></span><br><span class="line"><span class="string">        计算找到数组 Y 中与 x 距离最近的元素 y 的索引, </span></span><br><span class="line"><span class="string">        返回索引构成的数组</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 将两者相同簇的质心一一对应并按 mbk 质心的顺序封装成字典</span></span><br><span class="line">        ar = pairwise_distances_argmin(</span><br><span class="line">        mbk.cluster_centers_, kmeans.cluster_centers_)</span><br><span class="line">        dict_ = <span class="built_in">dict</span>(<span class="built_in">enumerate</span>(ar))</span><br><span class="line">        <span class="comment"># 用 mbk 的训练结果标签 y_hat 就可以寻找到对应的 kmeans 的质心</span></span><br><span class="line">        y_hat = pd.Series(y_hat).<span class="built_in">map</span>(dict_).values</span><br><span class="line">    <span class="comment"># 将预测结果加入到列表中</span></span><br><span class="line">    y_hat_list.append(y_hat)</span><br><span class="line">    </span><br><span class="line">    plt.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], c=colors[y_hat], marker=<span class="string">&#x27;.&#x27;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="https://wx2.sbimg.cn/2020/07/04/2OERm.md.png" alt="png"></p>
<p>比较两个算法聚类结果的差异:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">same = y_hat_list[<span class="number">0</span>] == y_hat_list[<span class="number">1</span>]</span><br><span class="line">diff = y_hat_list[<span class="number">0</span>] != y_hat_list[<span class="number">1</span>]</span><br><span class="line">plt.scatter(x[same, <span class="number">0</span>], x[same, <span class="number">1</span>], c=<span class="string">&#x27;g&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>, label=<span class="string">&#x27;预测相同&#x27;</span>)</span><br><span class="line">plt.scatter(x[diff, <span class="number">0</span>], x[diff, <span class="number">1</span>], c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>, label=<span class="string">&#x27;预测不同&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">print(<span class="string">&#x27;相同数量:&#x27;</span>, x[same].shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">&#x27;不同数量:&#x27;</span>, x[diff].shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>相同数量: 7983
不同数量: 17</code></pre>
<p><img src="https://wx2.sbimg.cn/2020/07/04/2Obyd.png" alt="png"></p>
<p>两个算法聚类结果只有 17 个样本点不同</p>
<br>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/284/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/284/">284</a><span class="page-number current">285</span><a class="page-number" href="/page/286/">286</a><span class="space">&hellip;</span><a class="page-number" href="/page/298/">298</a><a class="extend next" rel="next" href="/page/286/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备20041225号 </a>
      <img src="/images/beian.png" style="display: inline-block;"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44030702003010" rel="noopener" target="_blank">粤公网安备 44030702003010号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">吴昊</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>总字数：</span>
    <span title="总字数">298k</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  <script src="/js/local-search.js"></script>















  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


</body>
</html>
